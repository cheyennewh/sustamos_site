[{"path":"index.html","id":"about-and-section-guide","chapter":" 1 About and Section Guide","heading":" 1 About and Section Guide","text":"evolving booklet contains details Sustamos project. three sections comprise booklet describe experiment setup, current participant details, iterations main additional analyses project. breakdown section table contents.\nExperiment Info: Contains information experiments conducted part project. includes task design participant recruitment information.\n\nWhole-data analyses: Contains analyses data entire sample collected participants.\n\nreally one population?: Contains different attempts parsing participant data, performance either encoding memory portions experiment\n","code":""},{"path":"index.html","id":"about-the-project","chapter":" 1 About and Section Guide","heading":"1.1 About the project","text":"goal current project (codenamed Sustamos) understand simultaneous influence stimulus-derived individual-derived memory determinants can help us predict memory individuals.","code":""},{"path":"index.html","id":"stimulus-specific-memory-influencers","chapter":" 1 About and Section Guide","heading":"1.1.1 Stimulus-specific memory influencers","text":"Prior work shown memory stimulus, image predicted, part, measurable properties stimulus. properties image (e.x. luminance, color, shapes) associated capture bottom-attention increased chances successful encoding. steering attention absolute details paves way successful retrieval stimuli later point. Importantly, category image properties can easily measured visual inspection reliant observer interpretation.However, measurable stimulus properties determined simply stimulus isolation. Instead, also able understand stimulus ’s relative properties– take form placing stimulus context stimuli. Relative properties image’s uniqueness, unusualness, beauty emerge comparison stimuli dependent viewer’s experience prior stimuli make comparisons. Rather related purely sensory components stimuli, properties product implicit explicit memory similar stimuli. therefore influence encoding stimulus avenues automatic attention lassoing.","code":""},{"path":"index.html","id":"person-specific-memory-influencers","chapter":" 1 About and Section Guide","heading":"1.1.2 Person-specific memory influencers","text":"also able predict memory items understanding individual, rather simply understanding item remembered. Measurable trait-like properties, hold stable individual across time, state-like properties, fluctuate within individual time, can help us understand stimulus processed encoding, consolidation, retrieval. example, even image likely remembered due absolute relative properties, viewer may less likely remember due transient factors, attentional state viewing.","code":""},{"path":"experiment-info.html","id":"experiment-info","chapter":" 2 Experiment Info","heading":" 2 Experiment Info","text":"section contains information tasks included Sustamos experiments. ‘classic’ version experiment features 3 tasks: encoding, retrieval, valence/arousal rating tasks. three tasks completed part one session ‘classic’ version experiment. ‘delay’ version experiment, encoding task completed Part 1 experiment. retrieval valence/arousal ratings completed Part 2 study, made available participants 1 day completion Part 1.","code":""},{"path":"experiment-info.html","id":"classic","chapter":" 2 Experiment Info","heading":"2.1 Classic","text":"‘classic’ version Sustamos experiment 1-session/3 task experiment run Prolific hosted Gorilla. features 3 main tasks: encoding task, immediate retrieval task affective rating task. tasks described detail :encoding task ~10 minute go/-go task features stream scene images VAMOS set. Participants instructed respond key press images within stream. However, image periodically repeated stream back--back. instance, participant instructed withhold response.design, able get response time measures leading key repeated image (target image). also able gain mesures whether participants made error, lapse, critical back--back repeated images. measures later give us sense participant’s attentional state encoding task.Immediately following encoding task, participants must complete task tests memory encoding task target images. Participants asked rate memory target images scale 1(old)-6(new).Finally, participants must rate pleasantness intensity feeling evoked target memory lure images. image, participants asked first rate pleasantness scale 1(unpleasant) 9 (pleasant). Immediately , participants rate intensity feeling image scale 1(weak) 9 (strong).","code":""},{"path":"experiment-info.html","id":"encoding-task","chapter":" 2 Experiment Info","heading":"2.1.1 Encoding Task","text":"encoding task ~10 minute go/-go task features stream scene images VAMOS set. Participants instructed respond key press images within stream. However, image periodically repeated stream back--back. instance, participant instructed withhold response.design, able get response time measures leading key repeated image (target image). also able gain mesures whether participants made error, lapse, critical back--back repeated images. measures later give us sense participant’s attentional state encoding task.","code":""},{"path":"experiment-info.html","id":"retrieval-task","chapter":" 2 Experiment Info","heading":"2.1.2 Retrieval Task","text":"Immediately following encoding task, participants must complete task tests memory encoding task target images. Participants asked rate memory target images scale 1(old)-6(new).","code":""},{"path":"experiment-info.html","id":"affective-rating-task","chapter":" 2 Experiment Info","heading":"2.1.3 Affective Rating Task","text":"Finally, participants must rate pleasantness intensity feeling evoked target memory lure images. image, participants asked first rate pleasantness scale 1(unpleasant) 9 (pleasant). Immediately , participants rate intensity feeling image scale 1(weak) 9 (strong).","code":""},{"path":"experiment-info.html","id":"delay","chapter":" 2 Experiment Info","heading":"2.2 Delay","text":"‘delay’ version Sustamos experiment 2-session/3 task experiment run Prolific hosted Gorilla. features 3 main tasks: encoding task, delayed retrieval task affective rating task. tasks described detail :encoding task ~10 minute go/-go task features stream scene images VAMOS set. Participants instructed respond key press images within stream. However, image periodically repeated stream back--back. instance, participant instructed withhold response.delay version task, encoding portion completed session 1 2. task featured session 1.design, able get response time measures leading key repeated image (target image). also able gain mesures whether participants made error, lapse, critical back--back repeated images. measures later give us sense participant’s attentional state encoding task.Twenty-four hours completing session 1 experiment, participants return study complete session 2. retrieval task first task session 2. classic version, participants must complete task tests memory target images encoding task. Participants asked rate memory target images scale 1(old)-6(new).Finally, session 2 participants also give ratings participants must pleasantness intensity feeling evoked target memory lure images. image, participants asked first rate pleasantness scale 1(unpleasant) 9 (pleasant). Immediately , participants rate intensity feeling image scale 1(weak) 9 (strong).","code":""},{"path":"experiment-info.html","id":"encoding-task-1","chapter":" 2 Experiment Info","heading":"2.2.1 Encoding Task","text":"encoding task ~10 minute go/-go task features stream scene images VAMOS set. Participants instructed respond key press images within stream. However, image periodically repeated stream back--back. instance, participant instructed withhold response.delay version task, encoding portion completed session 1 2. task featured session 1.design, able get response time measures leading key repeated image (target image). also able gain mesures whether participants made error, lapse, critical back--back repeated images. measures later give us sense participant’s attentional state encoding task.","code":""},{"path":"experiment-info.html","id":"retrieval-task-1","chapter":" 2 Experiment Info","heading":"2.2.2 Retrieval Task","text":"Twenty-four hours completing session 1 experiment, participants return study complete session 2. retrieval task first task session 2. classic version, participants must complete task tests memory target images encoding task. Participants asked rate memory target images scale 1(old)-6(new).","code":""},{"path":"experiment-info.html","id":"affective-rating-task-1","chapter":" 2 Experiment Info","heading":"2.2.3 Affective Rating Task","text":"Finally, session 2 participants also give ratings participants must pleasantness intensity feeling evoked target memory lure images. image, participants asked first rate pleasantness scale 1(unpleasant) 9 (pleasant). Immediately , participants rate intensity feeling image scale 1(weak) 9 (strong).","code":""},{"path":"whole-data-analyses---delay.html","id":"whole-data-analyses---delay","chapter":" 3 Whole-Data Analyses - Delay","heading":" 3 Whole-Data Analyses - Delay","text":"section includes analyses sustained attention, recognition memory, affective rating data encoding retrieval components ‘delay’ version experiment described ‘Experiments’. participants sample included following analyses. analyses split task performance memory accuracy, see ‘populations’ tab.","code":""},{"path":"whole-data-analyses---delay.html","id":"how-often-were-participants-lapsing-on-the-task","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.1 How often were participants lapsing on the task?","text":"go/-go task (encoding task), participants withheld response saw second presentation target image. lapse occurs accidentally make key press one -go target images. 50 target images shown task participant, maximum number lapses 50. Scroll table see often participant made mistake.","code":""},{"path":"whole-data-analyses---delay.html","id":"does-pretrial-reaction-time-predict-lapses","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.2 Does pretrial reaction time predict lapses?","text":"average reaction times (RTs) linearly detrended within participant, mean reaction times calculated 3 images prior target (pretrial RT). plot, compare preceding window RT target images participant correctly withheld response (correct) lapsed task. expect reaction times correct condition slower lapse condition. indicate participants reacting habitually vs. reactively images lapse.comparison, see , general, reaction time slower correct vs. lapse conditions, line prior findings.","code":""},{"path":"whole-data-analyses---delay.html","id":"is-memory-above-chance","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.3 Is memory above chance?","text":"retrieval task, participants asked rate memory target images (50 memory lures) scale 1 (sure old) - 6 (sure new). ensure data quality later analyses included participant memory data, first checked participant’s memory chance.\nalso took look distributions memory performance, using d’ ’prime’ measures performance. cases, ’s apparent ton participants hovering just chance. ‘populations’ section bookdown, explore whether ‘worse memory’ participants (median) produce significantly different results ‘better memory’ participants.","code":""},{"path":"whole-data-analyses---delay.html","id":"how-does-pretrial-reaction-time-relate-to-memory-after-a-24-hr-delay","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.4 How does pretrial reaction time relate to memory after a 24 hr delay?","text":"","code":"##               Estimate Std. Error     z value     Pr(>|z|)\n## (Intercept) 0.68878540 0.10821467 6.364990806 1.953014e-10\n## zrt         0.00044247 0.05194982 0.008517257 9.932043e-01## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n##  Family: binomial  ( logit )\n## Formula: hits ~ zrt + (1 + zrt | `Participant Private ID`)\n##    Data: delay_mem_att\n## \n##      AIC      BIC   logLik deviance df.resid \n##   2425.5   2453.4  -1207.8   2415.5     1936 \n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.2062 -1.0499  0.5641  0.7087  1.4035 \n## \n## Random effects:\n##  Groups                 Name        Variance Std.Dev. Corr \n##  Participant Private ID (Intercept) 0.366183 0.60513       \n##                         zrt         0.004221 0.06497  -0.18\n## Number of obs: 1941, groups:  Participant Private ID, 40\n## \n## Fixed effects:\n##              Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) 0.6887854  0.1082147   6.365 1.95e-10 ***\n## zrt         0.0004425  0.0519498   0.009    0.993    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##     (Intr)\n## zrt -0.033"},{"path":"whole-data-analyses---delay.html","id":"how-does-memorability-relate-to-memory-after-a-24-hr-delay","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.5 How does memorability relate to memory after a 24 hr delay?","text":"","code":"##                Estimate Std. Error    z value     Pr(>|z|)\n## (Intercept) 0.675400495 0.10999943 6.14003657 8.250248e-10\n## z_mem       0.005046484 0.05648632 0.08933993 9.288118e-01"},{"path":"whole-data-analyses---delay.html","id":"how-does-valence-relate-to-memory-after-a-24-hr-delay","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.6 How does valence relate to memory after a 24 hr delay?","text":"","code":"##                Estimate Std. Error    z value     Pr(>|z|)\n## (Intercept)  0.67541387 0.10999218  6.1405625 8.222979e-10\n## zv          -0.05156664 0.05264413 -0.9795327 3.273169e-01"},{"path":"whole-data-analyses---delay.html","id":"how-does-arousal-relate-to-memory-after-a-24-hr-delay","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.7 How does arousal relate to memory after a 24 hr delay?","text":"","code":"##                 Estimate Std. Error     z value     Pr(>|z|)\n## (Intercept)  0.672950686 0.10919460  6.16285708 7.144399e-10\n## za          -0.003134217 0.04931523 -0.06355475 9.493248e-01"},{"path":"whole-data-analyses---delay.html","id":"interactive-model","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.7.1 Interactive Model","text":"","code":"## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n##  Family: binomial  ( logit )\n## Formula: hits ~ zrt * zv * za * z_mem + (1 + zrt + zv + za + z_mem | `Participant Private ID`)\n##    Data: delay_mem_att\n## Control: glmerControl()\n## \n##      AIC      BIC   logLik deviance df.resid \n##   2456.5   2629.2  -1197.3   2394.5     1910 \n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.1477 -1.0095  0.5366  0.7046  1.7955 \n## \n## Random effects:\n##  Groups                 Name        Variance  Std.Dev. Corr                   \n##  Participant Private ID (Intercept) 0.3928954 0.62681                         \n##                         zrt         0.0002294 0.01515  -1.00                  \n##                         zv          0.0525080 0.22915  -0.36  0.36            \n##                         za          0.0017124 0.04138   0.99 -0.99 -0.25      \n##                         z_mem       0.0637406 0.25247  -0.18  0.18  0.98 -0.07\n## Number of obs: 1941, groups:  Participant Private ID, 40\n## \n## Fixed effects:\n##                  Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)      0.705591   0.112759   6.258 3.91e-10 ***\n## zrt             -0.015959   0.055124  -0.290    0.772    \n## zv              -0.019656   0.069367  -0.283    0.777    \n## za              -0.045316   0.058903  -0.769    0.442    \n## z_mem            0.006983   0.068025   0.103    0.918    \n## zrt:zv          -0.005477   0.058646  -0.093    0.926    \n## zrt:za           0.070867   0.056160   1.262    0.207    \n## zv:za           -0.080767   0.051261  -1.576    0.115    \n## zrt:z_mem       -0.033959   0.058713  -0.578    0.563    \n## zv:z_mem        -0.022992   0.059257  -0.388    0.698    \n## za:z_mem         0.067731   0.059847   1.132    0.258    \n## zrt:zv:za        0.019130   0.049349   0.388    0.698    \n## zrt:zv:z_mem    -0.049863   0.060824  -0.820    0.412    \n## zrt:za:z_mem    -0.061504   0.064691  -0.951    0.342    \n## zv:za:z_mem     -0.024430   0.054438  -0.449    0.654    \n## zrt:zv:za:z_mem  0.034737   0.058035   0.599    0.549    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## optimizer (Nelder_Mead) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')##                     Estimate Std. Error     z value     Pr(>|z|)\n## (Intercept)      0.705590942 0.11275887  6.25752067 3.911458e-10\n## zrt             -0.015958711 0.05512435 -0.28950381 7.721959e-01\n## zv              -0.019656400 0.06936667 -0.28336952 7.768936e-01\n## za              -0.045315522 0.05890333 -0.76932026 4.417032e-01\n## z_mem            0.006982622 0.06802534  0.10264736 9.182429e-01\n## zrt:zv          -0.005476557 0.05864630 -0.09338282 9.255994e-01\n## zrt:za           0.070867299 0.05616003  1.26188150 2.069914e-01\n## zv:za           -0.080767224 0.05126073 -1.57561589 1.151144e-01\n## zrt:z_mem       -0.033959130 0.05871343 -0.57838783 5.630023e-01\n## zv:z_mem        -0.022991936 0.05925714 -0.38800280 6.980140e-01\n## za:z_mem         0.067730718 0.05984679  1.13173526 2.577458e-01\n## zrt:zv:za        0.019129714 0.04934888  0.38764235 6.982807e-01\n## zrt:zv:z_mem    -0.049863288 0.06082374 -0.81979979 4.123303e-01\n## zrt:za:z_mem    -0.061503847 0.06469107 -0.95073167 3.417406e-01\n## zv:za:z_mem     -0.024430161 0.05443793 -0.44877090 6.535969e-01\n## zrt:zv:za:z_mem  0.034736849 0.05803542  0.59854570 5.494759e-01"},{"path":"whole-data-analyses---delay.html","id":"how-quickly-are-participants-completing-the-memory-task","chapter":" 3 Whole-Data Analyses - Delay","heading":"3.7.2 How quickly are participants completing the memory task?","text":"","code":""},{"path":"whole-data-analyses---classic.html","id":"whole-data-analyses---classic","chapter":" 4 Whole-Data Analyses - Classic","heading":" 4 Whole-Data Analyses - Classic","text":"section includes analyses sustained attention, recognition\nmemory, affective rating data encoding retrieval\ncomponents ‘classic’ version experiment described \n‘Experiments’. participants sample included \nfollowing analyses. analyses split task performance memory\naccuracy, see ‘populations’ tab.complete models predicts memory function 1) 4 predictors 2) interactions main predictors. also allows random intercepts individual randoms slopes given 4 predictors.\n\\(\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time}  + (1 \\text{ + Reaction Time} \\\\ \\text{+Valence+Arousal+Memorability}\\ \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\\)many, many models section, see \ninteraction often significant arousal \nmemorability. explored bit creating two way plot displays predicted memory image (memory individuals) vs. memorability \nimage (across-population memory) split plot high low arousing groups. Note \npredicted memory comes models formula:\n\\(\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time}+(1 \\text{ + Reaction Time}\\\\ \\text{+Valence+Arousal+Memorability}\\ \\mid \\text{Participant}), \\text{family=binomial}\\).complete model also showed interaction memorability arousal may modulated valence, also created three-way version plot. Using complete formula, predictions individual memory made. predictions separated negative, positive, neutral bins.predicted memory image plotted memorability image. line colors represent arousal groups (high/low). plots show \ninteraction memorability arousal influences memory\npredictions valence bin.","code":""},{"path":"whole-data-analyses---classic.html","id":"how-often-were-participants-lapsing-on-the-task-1","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.1 How often were participants lapsing on the task?","text":"go/-go task (encoding task), participants \nwithheld response saw second presentation target\nimage. lapse occurs accidentally make key press one \n-go target images. 50 target images shown \ntask participant, maximum number lapses 50. Scroll\ntable see often participant made mistake.","code":""},{"path":"whole-data-analyses---classic.html","id":"does-pretrial-reaction-time-predict-lapses-1","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.2 Does pretrial reaction time predict lapses?","text":"average reaction times (RTs) linearly detrended within\nparticipant, mean reaction times calculated 3 images\nprior target (pretrial RT). plot, compare \npreceding window RT target images participant correctly\nwithheld response (correct) lapsed task. \nexpect reaction times correct condition \nslower lapse condition. indicate \nparticipants reacting habitually vs. reactively images \nlapse.comparison, see , general, reaction time slower\ncorrect vs. lapse conditions, line prior\nfindings.","code":""},{"path":"whole-data-analyses---classic.html","id":"is-memory-above-chance-1","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.3 Is memory above chance?","text":"retrieval task, participants asked rate memory\ntarget images (50 memory lures) scale 1 (sure old) - 6\n(sure new). ensure data quality later analyses included\nparticipant memory data, first checked participant’s memory\nchance. also took look distributions memory performance,\nusing d’ ’prime’ measures performance. cases,\n’s apparent ton participants hovering\njust chance. ‘populations’ section bookdown, \nexplore whether ‘worse memory’ participants (median) produce\nsignificantly different results ‘better memory’ participants.","code":""},{"path":"whole-data-analyses---classic.html","id":"is-pretrial-rt-predictive-of-memory","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.4 Is pretrial RT predictive of memory?","text":"item considered accurately remembered (‘hit’) \nparticipant responded 1-3 memory rating task \ntarget. Responses 3 lower therefore taken ‘hit’ \nresponses 4 higher calculated ‘miss’. , plot \nparticipant-specific predictions image recognition using mixed\neffect logistic regression model just pretrial reaction time \npredictor. model included random slopes intercepts \nparticipant predicted memory using binomial method. Values 1 \ny axis represent ‘hit’ 0 represents ‘miss’.Overall, positive relationship pretrial reaction time\nmemory. indicate participants better\nattentional state prior viewing target (positive values x axis)\nlikely correctly remember target later ( higher\nvalues y axis). Model Formula: {\\[\n\\text{hit} \\sim   \\text{(Reaction Time} + \\text{(1+Reaction Time|Participant)} \\text{, family=\"binomial\")}\n\\]}","code":""},{"path":"whole-data-analyses---classic.html","id":"is-memorability-predictive-of-memory","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.5 Is memorability predictive of memory?","text":"similar analysis conducted, using memorability (\nVAMOS) sole predictor ‘hit’ memory task \nindividual. analysis, memorability score z-scored globally.\nRandom intercepts included mixed model, participant\nmay different baseline memory. However, memorability assumed \nimpact participants (less) equally, random slopes \nincluded.One expect images memorable across people \nalso memorable individual. find , indeed, \nmemorable images (positive values x axis) associated better\nmemory (higher values y axis).Model Formula:\n\\[\n\\text{hit} \\sim   \\text{(Memorability} + \\text{(1+Memorability|Participant)} \\text{, family=\"binomial\")}\n\\]","code":""},{"path":"whole-data-analyses---classic.html","id":"is-valence-predictive-of-memory","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.6 Is Valence Predictive of Memory?","text":"also interested exploring valence predict image\nrecognition model sole predictor. However, \ntime created 3 versions model:classic (VAMOS), individual\nrating, average rating versions.classic (VAMOS):  version \nmodel uses VAMOS-derived scores valence. come \nratings valence current experiment. Thus, predictor\nvariable z-scored within individual. Rather, z-scored\nglobally. model formula, random intercepts specified,\nassumed valence ratings VAMOS set can \nused ‘objective’ object properties. Though, ’m definitely open \npushback .individual rating: version \nmodel uses ratings valence supplied participants \ncurrent experiment. participant rated valence\ndifferently given image, image valence rating \nparticipant study. variable z-scored\nwithin-participant. random slopes intercepts included \nmodel.average rating: version model\nuses averaged participant ratings valence current\nexperiment. image single valence score mean \nratings image. variable z-scored\nwithin-group two experimental conditions. random slopes\nintercepts included model, though ’m really sure\ncorrect way .Model Formula:\n\\[\n\\text{hit} \\sim   \\text{(Valence} + \\text{(1 + Valence| Participant)} \\text{, family=\"binomial\")}\n\\]Model Formula:\n\\[\n\\text{hit} \\sim   \\text{(Valence} + \\text{(1+Valence| Participant)} \\text{, family=\"binomial\")}\n\\]Model Formula:\n\\[\n\\text{hit} \\sim   \\text{(Valence} + \\text{(1+Valence| Participant)} \\text{, family=\"binomial\")}\n\\]","code":""},{"path":"whole-data-analyses---classic.html","id":"is-arousal-predictive-of-memory","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.7 Is Arousal Predictive of Memory?","text":"completeness, also conducted 3 versions model predicting\nmemory using just arousal: classic (VAMOS), individual rating, \naverage rating versions.classic (VAMOS):  version \nmodel uses VAMOS-derived scores varousal. come \nratings arousal current experiment. Thus, predictor\nvariable z-scored within individual. Rather, z-scored\nglobally.individual rating: version \nmodel uses ratings valence derived participants \ncurrent experiment. participant rated arousal\ndifferently given image, image arousal rating \nparticipant study. variable z-scored\nwithin-participant.average rating: version model\nuses averaged ratings arousal current experiment. \nimage single arousal score mean ratings \nimage. variable z-scored within-group two\nexperimental conditions.Predictions memory versions model can \nfound , along model formulas model outputs. \nresults consistent across versions. VAMOS ratings,\nindividual ratings, averaged ratings,  arousing images \nmemorable less arousing images. Model Formula:\n\\[\n\\text{hit} \\sim   \\text{(Arousal} + \\text{(1 + Arousal | Participant)} \\text{, family=\"binomial\")}\n\\] Model Formula:\n\\[\n\\text{hit} \\sim   \\text{(Arousal} + \\text{(1 + Arousal| Participant)} \\text{, family=\"binomial\")}\n\\] Model Formula:\\[\n\\text{hit} \\sim   \\text{(Arousal} + \\text{(1+Arousal|Participant)} \\text{, family=\"binomial\")}\n\\]","code":""},{"path":"whole-data-analyses---classic.html","id":"memory-prediction-using-simultaneous-predictors-in-a-mixed-logistic-regression-model","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.8 Memory Prediction using Simultaneous Predictors in a Mixed Logistic Regression Model","text":"Finally, threw combinations 4 predictors (valence, arousal,\nattention, memorability) single model predictive \nmemory (binarized 1-6 scale) understand simultaneous\ninfluence affective ratings, memorability, sustained attention subsequent memory.\nanalyses, VAMOS valence arousal scores used \naffective variables. Model formula output trials can found .majority outputs, story : valence,\narousal, memorability, attention positively impact memory.\nImages positive, arousing, memorable likely \nremembered. Images see better attentional state \nalso better remembered. pattern holds true predicting binary\nmemory memory scale 1-6. interactions \nsignificant. Occasionally, memorability x arousal interaction became\nsignificant.\\[\n\\text{hit} \\sim   \\text{(Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} \\\\ + \\text{(1|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{Response(1-6)} \\sim \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + (1|\\text{Participant})\n\\]\\[\n\\text{hit} \\sim   \\text{(Memorability} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} \\\\ + \\text{(1|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{hit} \\sim   \\text{(Memorability} \\cdot \\text{Arousal} \\cdot \\text{Reaction Time} \\\\ + \\text{(1|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{hit} \\sim \\text{Memorability} + \\text{Arousal} + \\text{Reaction Time} + \\text{Valence}, + \\\\ \\text{(1|Participant),}\\\\ \\text{ family=\"binomial\"}\n\\]\\[\n\\text{hit} \\sim   \\text{(Arousal} + \\text{Valence} + \\text{Reaction Time} \\\\ + \\text{(1+Valence+Arousal|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{Response(1-6)} \\sim \\text{Arousal} + \\text{Valence} + \\text{Reaction Time} \\\\ + \\left(1 + \\text{Valence} + \\text{Arousal} \\mid \\text{Participant}\\right)\n\\]\\[\n\\text{hit} \\sim   \\text{(Memorability} + \\text{Valence} + \\text{Reaction Time} \\\\ + \\text{(1+Valence|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{hit} \\sim   \\text{(Memorability} + \\text{Arousal} + \\text{Reaction Time} \\\\ +  \\text{(1+Arousal|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{hit} \\sim   \\text{(Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} \\\\ + \\text{(1+Valence+Arousal|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{Response(1-6)} \\sim \\text{Arousal}  \\cdot \\text{Valence}  \\cdot \\text{Reaction Time} \\\\ + \\left(1 + \\text{Valence} + \\text{Arousal} \\mid \\text{Participant}\\right)\n\\]\\[\n\\text{hit} \\sim   \\text{(Memorability} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} \\\\ + \\text{(1+Valence|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{hit} \\sim   \\text{(Memorability} \\cdot \\text{Arousal} \\cdot \\text{Reaction Time} \\\\ + \\text{(1+Arousal|Participant)} \\text{, family=\"binomial\")}\n\\]\\[\n\\text{hit} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Reaction Time} + \\\\ \\text{(1+ Reaction Time|Participant),} \\text{ family=\"binomial\"}\n\\]\\[\n\\text{hit} \\sim \\text{Memorability} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + \\\\ \\text{(1+ Reaction Time|Participant),} \\text{ family=\"binomial\"}\n\\]\\[\n\\text{hit} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Reaction Time} \\cdot \\text{Valence} + \\text{1 + Reaction Time}, \\text{ family=\"binomial\"}\n\\]\\[\n\\text{hit} \\sim \\text{Memorability} + \\text{Arousal} + \\text{Reaction Time}  + \\text{(Memorability} \\cdot \\text{Reaction Time)} + \\text{(Memorability} \\cdot \\text{Arousal)}, \\text{ family=\"binomial\"}\n\\]<style=” text-align:center; vertical-align: middle; padding:40px\n0;“>\n\\[\n\\text{hit} \\sim \\text{Memorability} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} \\cdot \\text{Arousal}+ \\\\ \\text{(1+ Reaction Time+ Valence+Arousal+Memorability|Participant),} \\text{ family=\"binomial\"}\n\\]","code":""},{"path":"whole-data-analyses---classic.html","id":"how-do-these-results-compare-when-using-vamos-vs-individual-ratings-of-valence-and-arousal","chapter":" 4 Whole-Data Analyses - Classic","heading":"4.8.1 How do these results compare when using VAMOS vs individual ratings of valence and arousal?","text":"analyses, VAMOS scores (group-averaged prior study)\nused index affect evoked image. one\nimagine relationship affect, memory, \npredictors memory may change use ratings valence\narousal come participants completed \nmemory test using group-averaged ratings collection\nparticipants. Perhaps may able find idiosyncratic\ngroup-averaged ratings valence arousal may change might\npredict memory using regression models.Model w/ individual ratings valence & arousal\n\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + (1 + \\text{Arousal} + \\text{Valence} + \\text{Memorability} \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]investigate whether rating differences significantly\naffect interactive model outputs, ran set interactive models \nindividual ratings valence arousal used \n‘Valence’ ‘Arousal’ terms. z-scoring information, see \n‘individual rating’ subsection 3.6.\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + (1 + \\text{Arousal} + \\text{Valence} + \\text{Reaction Time}\\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + (1 + \\text{Arousal} + \\text{Valence} \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + (1 \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time}, \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal}  \\cdot \\text{Reaction Time} + (1 \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Valence}  \\cdot \\text{Reaction Time} + (1 \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\], ran similar set models using averaged participant ratings\nvalence/arousal ‘classic’ experiment measures valence\narousal. See ‘average rating’ subsection 3.6. \ninformation z-scoring averaging version.\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + (1 + \\text{Arousal} + \\text{Valence} + \\text{Reaction Time}\\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + (1 + \\text{Arousal} + \\text{Valence} \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time} + (1 \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Arousal} \\cdot \\text{Valence} \\cdot \\text{Reaction Time}, \\text{family=binomial}\n\\]\\[\n\\text{hits} \\sim \\text{Memorability} \\cdot \\text{Valence}  \\cdot \\text{Reaction Time} + (1 \\mid \\text{Participant.Private.ID}), \\text{family=binomial}\n\\]","code":"## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n##  Family: binomial  ( logit )\n## Formula: hits ~ z_mem * za * zv * zrt + (1 + za + zv | Participant.Private.ID)\n##    Data: group_av_emo\n## \n##      AIC      BIC   logLik deviance df.resid \n##   2943.3   3072.8  -1449.7   2899.3     2642 \n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.9546 -0.8646  0.4497  0.5987  1.4625 \n## \n## Random effects:\n##  Groups                 Name        Variance Std.Dev. Corr       \n##  Participant.Private.ID (Intercept) 0.531671 0.72916             \n##                         za          0.013183 0.11482  -0.98      \n##                         zv          0.003089 0.05558   0.19 -0.40\n## Number of obs: 2664, groups:  Participant.Private.ID, 95\n## \n## Fixed effects:\n##                 Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)      1.11876    0.09207  12.152  < 2e-16 ***\n## z_mem            0.13931    0.04972   2.802  0.00508 ** \n## za               0.07642    0.05300   1.442  0.14933    \n## zv               0.02902    0.05197   0.558  0.57653    \n## zrt              0.10240    0.05050   2.028  0.04259 *  \n## z_mem:za         0.05336    0.05185   1.029  0.30339    \n## z_mem:zv         0.19893    0.05001   3.977 6.97e-05 ***\n## za:zv           -0.10370    0.04950  -2.095  0.03616 *  \n## z_mem:zrt       -0.04465    0.05189  -0.860  0.38957    \n## za:zrt          -0.02010    0.05153  -0.390  0.69647    \n## zv:zrt           0.04019    0.05149   0.780  0.43511    \n## z_mem:za:zv     -0.12179    0.05033  -2.420  0.01552 *  \n## z_mem:za:zrt     0.01581    0.05255   0.301  0.76348    \n## z_mem:zv:zrt     0.11507    0.05275   2.182  0.02913 *  \n## za:zv:zrt       -0.05943    0.05224  -1.138  0.25526    \n## z_mem:za:zv:zrt -0.02629    0.05337  -0.493  0.62227    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## optimizer (Nelder_Mead) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 0.0105266 (tol = 0.002, component 1)"}]
